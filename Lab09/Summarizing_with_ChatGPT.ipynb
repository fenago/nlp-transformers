{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_QjF04i9neT"
      },
      "source": [
        "#Summarizing_with_ChatGPT\n",
        "Copyright 2023 Denis Rothman, MIT License\n",
        "\n",
        "**March 2023 message by Denis Rothman:**\n",
        "This notebook replaces[Training_OpenAI_GPT_2_CH09.ipynb](https://github.com/fenago/nlp-transformers/blob/main/Lab09/Training_OpenAI_GPT_2_CH09.ipynb). Google Colab does not support Tensorflow 1.x anymore which makes the Training_OpenAI_GPT_2_CH09.ipybn notebook unstable.\n",
        "\n",
        "The goal of *Transformers for NLP,  Lab 9, Matching Tokenizers and Datasets*, is to show how tokenizing works and the limitations of transformer models when embedding tokens.\n",
        "\n",
        "This notebook shows how to use GPT-3.5(ChatGPT) with the OpenAI API to perform the summarization task of lab 9, experimenting with rare words and showing the limits of SOA transformers no matter how evolved they are:\n",
        "\n",
        "1. Installing openai and your API key<br>\n",
        "2. Summarization<br>\n",
        "3. Tokenizing<br>\n",
        "4. Exploring the limits<br>\n",
        "5. Conclusion<br>\n",
        "\n",
        "To get the best out of this notebook:\n",
        "\n",
        "*  make sure you have read Lab 7\n",
        "\n",
        "*  once you have understood the theory, go to section 4 of this notebook,  *4. Exploring the limits*, of this notebook and try to find more limitations and think of how you can filter them and find solutions.\n",
        "\n",
        "**December 4,2023 OpenAI API update** \n",
        "\n",
        "API Chat completion call changed from ```openai.ChatCompletion.create``` to ```client.chat.completions.create with client= [YOUR OPENAI CLIENT]```\n",
        "\n",
        "Also to print the content of the response use : ```print(response.choices[0].message.content)```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUn5YJeQvy-F",
        "outputId": "5b83f807-740a-446e-cadd-24a70a070519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (23.0.1)\n",
            "Collecting pip\n",
            "  Downloading pip-23.1.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.0.1\n",
            "    Uninstalling pip-23.0.1:\n",
            "      Successfully uninstalled pip-23.0.1\n",
            "Successfully installed pip-23.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-crABM8l3Xi"
      },
      "source": [
        "#1.Installing openai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygFUriSCvTNb"
      },
      "source": [
        "## installing and importing openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G79pIy_Mg5Y",
        "outputId": "9a3ec088-ea60-4ff5-a8dd-7a2c28b6f333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.3/269.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 yarl-1.9.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#Importing openai\n",
        "try:\n",
        "  import openai\n",
        "except:\n",
        "  !pip install openai\n",
        "  import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7YHxHaLmAEi"
      },
      "source": [
        "##API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb6gFplQqU5v",
        "outputId": "d7713d84-0775-41f9-fe1a-8ec71562a39b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#2.API Key\n",
        "#Store you key in a file and read it(you can type it directly in the notebook but it will be visible for somebody next to you)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "API_KEY=f.readline()\n",
        "f.close()\n",
        "\n",
        "#The OpenAI Key\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U03EQHLtmZLl"
      },
      "source": [
        "#2. gpt-3.5 turbo(ChatGPT) dialog function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1moBmYTVp-ih"
      },
      "source": [
        "preparing the NLP message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wl_ih8tPqebL"
      },
      "outputs": [],
      "source": [
        " def dialog(uinput):\n",
        "   #preparing the prompt for OpenAI \n",
        "   role=\"user\"\n",
        "   \n",
        "   #prompt=\"Where is Tahiti located?\" #maintenance or if you do not want to use a microphone\n",
        "   line = {\"role\": role, \"content\": uinput}\n",
        "\n",
        "   #creating the mesage\n",
        "   assert1={\"role\": \"system\", \"content\": \"You are a Natural Language Processing Assistant.\"}\n",
        "   assert2={\"role\": \"assistant\", \"content\": \"You are helping viewers analyze social medial better.\"}\n",
        "   assert3=line\n",
        "   iprompt = []\n",
        "   iprompt.append(assert1)\n",
        "   iprompt.append(assert2)\n",
        "   iprompt.append(assert3)\n",
        "\n",
        "   #sending the message to ChatGPT\n",
        "   import os\n",
        "   from openai import OpenAI\n",
        "\n",
        "   client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        "    )\n",
        "\n",
        "   response=client.chat.completions.create(model=\"gpt-3.5-turbo\",messages=iprompt) #ChatGPT dialog\n",
        "\n",
        "   return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-qY6V3mqMEb"
      },
      "source": [
        "# 3.Summarizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKnTT3-j3TjG"
      },
      "source": [
        "The next to summarize:\n",
        "\n",
        "\"During such processes, cells sense the environment and respond to external factors that induce a certain direction of motion towards specific targets (taxis): this results in a persistent migration in a certain preferential direction. The guidance cues leading to directed migration may be biochemical or biophysical. Biochemical cues can be, for example, soluble factors or growth factors that give rise to chemotaxis, which involves a mono-directional stimulus. Other cues generating mono-directional stimuli include, for instance, bound ligands to the substratum that induce haptotaxis, durotaxis, that involves migration towards regions with an increasing stiffness of the ECM, electrotaxis, also known as galvanotaxis, that prescribes a directed motion guided by an electric field or current, or phototaxis, referring to the movement oriented by a stimulus of light [34]. Important biophysical cues are some of the properties of the extracellular matrix (ECM), first among all the alignment of collagen fibers and its stiffness. In particular, the fiber alignment is shown to stimulate contact guidance [22, 21].\"\n",
        "\n",
        "\n",
        "The summary by ChatGPT seems acceptable but implementing controlls by an SME(Subject Matter Expert) is good practice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM6fWKbit8qV",
        "outputId": "17a4c88b-65b9-48d5-f28f-cda2fafdc206"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Viewer request Summarize the following paragraph: During such processes, cells sense the environment and respond to external factors that induce a certain direction of motion towards specific targets (taxis): this results in a persistent migration in a certain preferential direction. The guidance cues leading to directed migration may be biochemical or biophysical. Biochemical cues can be, for example, soluble factors or growth factors that give rise to chemotaxis, which involves a mono-directional stimulus. Other cues generating mono-directional stimuli include, for instance, bound ligands to the substratum that induce haptotaxis, durotaxis, that involves migration towards regions with an increasing stiffness of the ECM, electrotaxis, also known as galvanotaxis, that prescribes a directed motion guided by an electric field or current, or phototaxis, referring to the movement oriented by a stimulus of light [34]. Important biophysical cues are some of the properties of the extracellular matrix (ECM), first among all the alignment of collagen fibers and its stiffness. In particular, the fiber alignment is shown to stimulate contact guidance [22, 21].\n",
            "ChatGPT response: Cells can move in a specific, preferred direction in response to external factors or stimuli such as biochemical and biophysical cues. Biochemical cues include soluble or bound factors, while biophysical cues include properties of the extracellular matrix (ECM) such as the alignment of collagen fibers and its stiffness. These cues can induce chemotaxis, haptotaxis, durotaxis, electrotaxis, or phototaxis, resulting in directed cell migration. The alignment of collagen fibers in the ECM is known to stimulate contact guidance.\n"
          ]
        }
      ],
      "source": [
        "uinput=\"Summarize the following paragraph: During such processes, cells sense the environment and respond to external factors that induce a certain direction of motion towards specific targets (taxis): this results in a persistent migration in a certain preferential direction. The guidance cues leading to directed migration may be biochemical or biophysical. Biochemical cues can be, for example, soluble factors or growth factors that give rise to chemotaxis, which involves a mono-directional stimulus. Other cues generating mono-directional stimuli include, for instance, bound ligands to the substratum that induce haptotaxis, durotaxis, that involves migration towards regions with an increasing stiffness of the ECM, electrotaxis, also known as galvanotaxis, that prescribes a directed motion guided by an electric field or current, or phototaxis, referring to the movement oriented by a stimulus of light [34]. Important biophysical cues are some of the properties of the extracellular matrix (ECM), first among all the alignment of collagen fibers and its stiffness. In particular, the fiber alignment is shown to stimulate contact guidance [22, 21].\"\n",
        "response=dialog(uinput) #preparing the messages for ChatGPT\n",
        "print(\"Viewer request\",uinput)\n",
        "print(\"ChatGPT response:\",response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPgasm5AvZi2"
      },
      "source": [
        "# 4.Exploring the limits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bL9Aa3S7F4E"
      },
      "source": [
        "In chapter, GPT-2 struggles with \"amoeboid\". GPT-3.5 turbo(ChatGPT) finds the correct definition even in a difficult sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V35q2q7Z5e6X",
        "outputId": "faf7a6d5-a908-4424-952f-68e2953d9ce7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Viewer request Explain this sentence: I don't use a false foot to move forward so I am not an amoeboid today.\n",
            "ChatGPT response: This sentence uses a metaphor that compares the speaker to an amoeboid organism. Amoebas are single-celled organisms that move by extending part of their body forward, and then flowing into the space it created. So, by saying \"I don't use a false foot to move forward,\" the speaker is implying that they don't pretend to be something they are not, and they don't manipulate their surroundings in a clever way to get ahead. Therefore, they conclude that they are not like an amoeba today, meaning they don't feel like they are acting in a dishonest or manipulative way to get ahead.\n"
          ]
        }
      ],
      "source": [
        "#amoeboid \n",
        "uinput=\"Explain this sentence: I don't use a false foot to move forward so I am not an amoeboid today.\"\n",
        "response=dialog(uinput) #preparing the messages for ChatGPT\n",
        "print(\"Viewer request\",uinput)\n",
        "print(\"ChatGPT response:\",response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI5dlRMa8PNJ"
      },
      "source": [
        "ChatGPT struggles with  [\"icing\" in hockey](https://www.merriam-webster.com/dictionary/icing)\n",
        "\n",
        "\"pucks\" is translated as nonesense in Frence as of March 15th, 2023. This might improve in the future.\n",
        "\n",
        "Viewer request English to French: Icing pucks is fun!\n",
        "ChatGPT response: Glaçage des rondelles est amusant!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_J0HzHa7V83",
        "outputId": "931488f6-77d8-409e-9523-44000e89f807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Viewer request English to French: Icing pucks is fun!\n",
            "ChatGPT response: Le glaçage des rondelles est amusant !\n"
          ]
        }
      ],
      "source": [
        "#The verb to ice pucks\n",
        "uinput=\"English to French: Icing pucks is fun!\"\n",
        "response=dialog(uinput) #preparing the messages for ChatGPT\n",
        "print(\"Viewer request\",uinput)\n",
        "print(\"ChatGPT response:\",response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0fLQ9Gf9bA0"
      },
      "source": [
        "The back translation produces nonesense:\n",
        "\n",
        "Viewer request French to English: \"Glaçage des rondelles est amusant!!\"\n",
        "ChatGPT response: \"Icing the slices is fun!!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HzIAAs19UOd",
        "outputId": "abfc97d2-d33d-480f-f9af-368297db646f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Viewer request French to English: Glaçage des rondelles est amusant!!\n",
            "ChatGPT response: \"Icing the cookies is fun!!\"\n"
          ]
        }
      ],
      "source": [
        "#The verb to ice pucks\n",
        "uinput=\"French to English: Glaçage des rondelles est amusant!!\"\n",
        "response=dialog(uinput) #preparing the messages for ChatGPT\n",
        "print(\"Viewer request\",uinput)\n",
        "print(\"ChatGPT response:\",response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czjyu19-9i7q"
      },
      "source": [
        "# 5.Conclusion\n",
        "\n",
        "GPT-2 has reached it limits.\n",
        "\n",
        "GPT-3.5 turbo(ChatGPT) represents a huge step forward.\n",
        "\n",
        "We simply have to accept the limitations and provide altternative solutions when we reach them.\n",
        "\n",
        "There is still much work to do!\n",
        "\n",
        "Next Steps: Explore SOA examples in the [BONUS](https://github.com/fenago/nlp-transformers/blob/main/Bonus/Readme.md) section! See what they can do and take them to their limits!\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
