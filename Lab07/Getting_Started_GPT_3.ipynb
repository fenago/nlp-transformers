{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPM-W5IVxfJS"
      },
      "source": [
        "# Getting Started with GPT-3 Engines\n",
        "\n",
        "copyright 2023 Denis Rothman \n",
        "\n",
        "**September 10,2023 update**\n",
        "\n",
        "As of January 4,2024, [OpenAI deprecations](https://platform.openai.com/docs/deprecations) apply to ```davinci```. The recommended replacement is ```davinci-002``` which has been implemented in this notebook.\n",
        "\n",
        "**December 4,2023 update**\n",
        "\n",
        "1.Cohere(language functions) and tiktoken(BPE tokenizer) required to install OpenAI\n",
        "\n",
        "2.API call changed from ```openai.Completion.create``` to ```openai.completions.create``` \n",
        "\n",
        "3.API call changed from ```engine=[model name]``` to ```model=[model name]```\n",
        "\n",
        "4.Response print changed from ```r=response[‚Äúchoice‚Äù][0] \\n print(r[‚Äútext‚Äù])``` to ```print(response.choices[0].text)```\n",
        "\n",
        "5.API Chat completion call changed from ```openai.ChatCompletion.create``` to ```client.chat.completions.create```  with client= [YOUR OPENAI CLIENT]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1yf-ju9P62Zb"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image     #This is used for rendering images in the notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7HO_zOAaA-Y"
      },
      "source": [
        "## Step 1: Installing & importing OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# December 4,2023 update : Tiktoken required to install OpenAI\n",
        "# Tiktoken is a fast BPE tokenizer\n",
        "!pip install tiktoken\n",
        "\n",
        "# December 4,2023 update : Cohere required to install OpenAI to implement language AI.\n",
        "# Cohere platform: https://dashboard.cohere.com/\n",
        "!pip install --upgrade cohere "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qS_Qk62FxclT"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import openai\n",
        "except:\n",
        "  !pip install openai\n",
        "  import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnKbbxVMaYqy"
      },
      "source": [
        "## Step 2: Entering the API KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6uKDkb3y7QZ"
      },
      "outputs": [],
      "source": [
        "#You can retrieve your API key from a file(1)\n",
        "# or enter it manually(2)\n",
        "\n",
        "#Comment this cell if you want to enter your key manually.\n",
        "#(1)Retrieve the API Key from a file\n",
        "#Store you key in a file and read it(you can type it directly in the notebook but it will be visible for somebody next to you)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "API_KEY=f.readline()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8cmujpyxKjj"
      },
      "outputs": [],
      "source": [
        "#(2) Enter your manually by\n",
        "# replacing API_KEY by your key.\n",
        "#The OpenAI Key\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6d0bggZX_dw"
      },
      "source": [
        "## Step 3: Running an NLP tasks with the default parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKwqIwACcB2B"
      },
      "source": [
        "## Step 4: Example 1: Grammar correction\n",
        "\n",
        "https://beta.openai.com/examples/default-grammar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pkZrsEzzNwS"
      },
      "outputs": [],
      "source": [
        "response = openai.completions.create(\n",
        "  model=\"davinci-002\",\n",
        "  prompt=\"Original: She no went to the market.\\nStandard American English:\",\n",
        "  temperature=0,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyUWe4elUzXp",
        "outputId": "4e0fda27-b766-4629-9941-96e2ea0fedba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \" She didn't go to the market.\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1642322148,\n",
            "  \"id\": \"cmpl-4QvIqMCmFgAQKGKDaony4B7wTQtSz\",\n",
            "  \"model\": \"davinci:2020-05-03\",\n",
            "  \"object\": \"text_completion\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "#displaying the response object\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpWrXf0LU3k6",
        "outputId": "9ea5b7bc-9432-41d8-fda4-5f201d1388f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " She didn't go to the market.\n"
          ]
        }
      ],
      "source": [
        "# retrieving the value of \"text\" in the dicionary\n",
        "print(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh1AuRliZVfS"
      },
      "source": [
        "## Example 2: Translation\n",
        "\n",
        "https://beta.openai.com/examples/default-translate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXh8vAb3M2ob",
        "outputId": "4ea92040-76c0-4ff7-ea05-984ddd12a744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Elle n'est pas all√©e au march√©.\n"
          ]
        }
      ],
      "source": [
        "response = openai.completions.create(\n",
        "  model=\"davinci-002\",\n",
        "  prompt=\"Original: She no went to the market.\\n French with no contractions:\",\n",
        "  temperature=0, \n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "print(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMUpe35ZA-t"
      },
      "source": [
        "## Example 3: Instructions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2oL0NLRNI3a",
        "outputId": "de330d73-7036-47bc-a5ce-d94eed1c7c44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "1. Start Internet Explorer.\n",
            "2. Click on the tools menu.\n",
            "3. Click on the Internet options.\n",
            "4. Click on the advanced tab.\n",
            "5. Click to clear or select the enable personalized favorite menu check box.\n"
          ]
        }
      ],
      "source": [
        "response = openai.completions.create(\n",
        "  model=\"davinci-002\",\n",
        "  prompt=\"Write a plan of actions based on these instructions:\\n\\nStart Internet Explorer.\\nYou need to eventually click on the advanced tab.\\nBut before that, click on the Internet options on the tools menu.\\nAfter the click on the advanced tab, click to clear or select the enable\\npersonalized favorite menu check box.\\n\\n\\nACTIONS:\",\n",
        "  temperature=0,\n",
        "  max_tokens=120,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWGCjioUawKp"
      },
      "source": [
        "## Example 4: Movie to emoji\n",
        "\n",
        "https://beta.openai.com/examples/default-movie-to-emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUOH-fAbawlc",
        "outputId": "c32d5b15-717b-4c28-cc53-bc64b23e3fd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " üï∑üï∏üï∑üï∏\n"
          ]
        }
      ],
      "source": [
        "response = openai.completions.create(\n",
        "  model=\"davinci-002\",\n",
        "  prompt=\"Back to Future: üë®üë¥üöóüïí\\nBatman: ü§µü¶á\\nTransformers: üöóü§ñ\\nWonder Woman: üë∏üèªüë∏üèºüë∏üèΩüë∏üèæüë∏üèø\\nWinnie the Pooh: üêªüêºüêª\\nThe Godfather: üë®üë©üëßüïµüèª‚Äç‚ôÇÔ∏èüë≤üí•\\nGame of Thrones: üèπüó°üó°üèπ\\nSpider-Man:\",\n",
        "  temperature=0.8,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "print(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8QgB1Phg0_k",
        "outputId": "a72519c4-a378-4e97-9e93-b59fa2681777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " üì∑üå¥üå¥üå¥üì∑\n"
          ]
        }
      ],
      "source": [
        "response = openai.completions.create(\n",
        "  model=\"davinci-002\",\n",
        "  prompt=\"Back to Future: üë®üë¥üöóüïí\\nBatman: ü§µü¶á\\nTransformers: üöóü§ñ\\nWonder Woman: üë∏üèªüë∏üèºüë∏üèΩüë∏üèæüë∏üèø\\nWinnie the Pooh: üêªüêºüêª\\nThe Godfather: üë®üë©üëßüïµüèª‚Äç‚ôÇÔ∏èüë≤üí•\\nGame of Thrones: üèπüó°üó°üèπ\\nSpider-Man: üï∑üï∏üï∑üï∏\\nAvatar:\",\n",
        "  temperature=0.8,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "print(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrS3kT-ebaT9"
      },
      "source": [
        "## Example 5: December 4, 2023 update\n",
        "\n",
        "OpenAI model updates: although davinci-002 can perform many tasks, gpt-4 is a better alternative for coding.\n",
        "\n",
        "The former example:\n",
        "*Programming language to another language*\n",
        "\n",
        "is replaced by:\n",
        "Natural Language to SQL \n",
        "\n",
        "https://platform.openai.com/playground/p/default-sql-translate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPIDVEVfbZ1x",
        "outputId": "2d96bd3c-26b4-491f-c96a-8185ef2d0196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "javascript\n",
            "\n",
            "// Now we can use the function in Javascript\n",
            "\n",
            "var predict_proba = function(X: Iterable[str]):\n",
            "    return np.array([predict_one_probas(tweet) for tweet in X])\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    { #defining a role for the model\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Given the following SQL tables, your job is to write queries given a user‚Äôs request.\\n\\nCREATE TABLE Orders (\\n  OrderID int,\\n  CustomerID int,\\n  OrderDate datetime,\\n  OrderTime varchar(8),\\n  PRIMARY KEY (OrderID)\\n);\\n\\nCREATE TABLE OrderDetails (\\n  OrderDetailID int,\\n  OrderID int,\\n  ProductID int,\\n  Quantity int,\\n  PRIMARY KEY (OrderDetailID)\\n);\\n\\nCREATE TABLE Products (\\n  ProductID int,\\n  ProductName varchar(50),\\n  Category varchar(50),\\n  UnitPrice decimal(10, 2),\\n  Stock int,\\n  PRIMARY KEY (ProductID)\\n);\\n\\nCREATE TABLE Customers (\\n  CustomerID int,\\n  FirstName varchar(50),\\n  LastName varchar(50),\\n  Email varchar(100),\\n  Phone varchar(20),\\n  PRIMARY KEY (CustomerID)\\n);\"\n",
        "    },\n",
        "    { #defining the request\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Write a SQL query which computes the average total order value for all orders on 2023-04-01.\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=1024,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNY5uUu6ead0"
      },
      "source": [
        "## Example 6: Advanced Tweet classifier\n",
        "\n",
        "https://beta.openai.com/examples/default-tweet-classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDeD3FkbearQ",
        "outputId": "339b2dec-47a8-439c-cf10-98f3533d38b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Negative\n",
            "2. Negative\n",
            "3. Positive\n",
            "4. Positive\n",
            "5. Negative\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = openai.completions.create(\n",
        "  model=\"davinci-002\",\n",
        "  prompt=\"This is a tweet sentiment classifier\\nTweet: \\\"I loved the new Batman movie!\\\"\\nSentiment: Positive\\n###\\nTweet: \\\"I hate it when my phone battery dies\\\"\\nSentiment: Negative\\n###\\nTweet: \\\"My day has been üëç\\\"\\nSentiment: Positive\\n###\\nTweet: \\\"This is the link to the article\\\"\\nSentiment: Neutral\\n###\\nTweet text\\n\\n\\n1. \\\"I loved the new Batman movie!\\\"\\n2. \\\"I hate it when my phone battery dies\\\"\\n3. \\\"My day has been üëç\\\"\\n4. \\\"This is the link to the article\\\"\\n5. \\\"This new music video blew my mind\\\"\\n\\n\\nTweet sentiment ratings:\\n1: Positive\\n2: Negative\\n3: Positive\\n4: Neutral\\n5: Positive\\n\\n\\n###\\nTweet text\\n\\n\\n1. \\\"I can't stand homework\\\"\\n2. \\\"This sucks. I'm bored üò†\\\"\\n3. \\\"I can't wait for Halloween!!!\\\"\\n4. \\\"My cat is adorable ‚ù§Ô∏è‚ù§Ô∏è\\\"\\n5. \\\"I hate chocolate\\\"\\n\\n\\nTweet sentiment ratings:\\n1.\",\n",
        "  temperature=0.3,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"###\"]\n",
        ")\n",
        "print(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIR6AhJhFvEE",
        "outputId": "618bfc31-5d16-4c8e-eed4-1fbd66d426b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¬†\"semiotics is the study of signs and symbols\"\n"
          ]
        }
      ],
      "source": [
        "response = openai.completions.create(\n",
        "  model=\"davinci-002\",\n",
        "  prompt=\"This is a tweet sentiment classifier\\nSentence: \\\"What does semiotics mean?\\\"\\n\\nA: \",\n",
        "  temperature=0,\n",
        "  max_tokens=100,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "print(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-Qiw1mjcmd6"
      },
      "source": [
        "## Example 7: Q&A\n",
        "\n",
        "https://beta.openai.com/examples/default-qa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh9hcKvrcobu",
        "outputId": "a529684c-3767-453e-bf99-1f9ab5cd48f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¬†Semiotics is the study of signs and symbols.\n"
          ]
        }
      ],
      "source": [
        "response = openai.completions.create(\n",
        "  model=\"davinci-002\",\n",
        "  prompt=\"Q: What does semiotics mean?\\nA: Semiotics is the study of signs and symbols.\\n\\nA: \",\n",
        "  temperature=0,\n",
        "  max_tokens=100,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "print(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P6zd0J8dYuT"
      },
      "source": [
        "## Example 8 : Summarize a text\n",
        "\n",
        "https://beta.openai.com/examples/default-summarize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyLOtqjkdZGD",
        "outputId": "3c2e75e1-6c5e-4290-c9ef-1f5cb9b2cd31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jupiter is the fifth planet from the Sun. The fifth planet is the largest planet in the Solar System. Jupiter is a gas giant. It is two-and-a-half times bigger than all the other planets together. It is a bright object in the night sky, and it can be seen from Earth.\n",
            "Jupiter is named after the Roman god Jupiter. When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows.\n",
            "Jupiter is on average\n"
          ]
        }
      ],
      "source": [
        "response = openai.completions.create(\n",
        "  model=\"davinci-002\",\n",
        "  prompt=\"My second grader asked me what this passage means:\\n\\\"\\\"\\\"\\nJupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. It is named after the Roman god Jupiter.[19] When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows,[20] and is on average the third-brightest natural object in the night sky after the Moon and Venus.\\n\\\"\\\"\\\"\\nI rephrased it for him, in plain language a second grader can understand:\\n\\\"\\\"\\\"\\n\",\n",
        "  temperature=0.5,\n",
        "  max_tokens=100,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0.2,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\\"\\\"\\\"\"]\n",
        ")\n",
        "print(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr5vvsGzdvKA"
      },
      "source": [
        "## Example 9: Parse unstructured data\n",
        "\n",
        "https://beta.openai.com/examples/default-parse-data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9g8n0Zfdviy",
        "outputId": "accd7763-e18b-488f-e991-cac1dec10e4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Pounits | Bright green | Savory |\n",
            "| Loopnovas | Neon pink | Cotton candy |\n",
            "| Glowls | Pale orange | Sour |\n",
            "| Other | |\n"
          ]
        }
      ],
      "source": [
        "response = openai.completions.create(\n",
        "  model=\"davinci-002\",\n",
        "  prompt=\"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy. There are also loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits are a bright green color and are more savory than sweet. There are also plenty of loopnovas which are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\\n\\nPlease make a table summarizing the fruits from Goocrux\\n| Fruit | Color | Flavor |\\n| Neoskizzles | Purple | Sweet |\\n| Loheckles | Grayish blue | Tart |\\n\",\n",
        "  temperature=0,\n",
        "  max_tokens=100,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\\n\"]\n",
        ")\n",
        "print(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1WLppo5eDhg"
      },
      "source": [
        "## Example 10 : Calculate Time Complexity\n",
        "\n",
        "https://beta.openai.com/examples/default-time-complexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfvgh8sseDxi",
        "outputId": "76ff4652-fb80-4bdc-df5c-716bec90dd27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " O(nk).\n"
          ]
        }
      ],
      "source": [
        "response = openai.completions.create(\n",
        "  model=\"davinci-002\",\n",
        "  prompt=\"def foo(n, k):\\naccum = 0\\nfor i in range(n):\\n    for l in range(k):\\n        accum += i\\nreturn accum\\n\\\"\\\"\\\"\\nThe time complexity of this function is\",\n",
        "  temperature=0,\n",
        "  max_tokens=64,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "print(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZetplCF_gEny",
        "outputId": "86cf113f-afaf-4170-b29a-af69a7fd50a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Language|Difficulty\n",
            "C|Easy\n",
            "Java|Medium\n",
            "C++|Hard\n",
            "Perl|Easy\n",
            "Python|Easy\n",
            "Ruby|Easy\n",
            "PHP|Easy\n",
            "C#|Easy\n",
            "JavaScript|Easy\n",
            "VB.NET|Easy\n",
            "\n",
            "VB|Easy\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = openai.completions.create(\n",
        "  model=\"davinci-002\",\n",
        "  prompt=\"A single column spreadsheet of industry names:\\n\\n\\nIndustry|\\nAccounting/Finance\\nAdvertising/Public Relations\\nAerospace/Aviation\\nArts/Entertainment/Publishing\\nAutomotive\\nBanking/Mortgage\\nBusiness Development\\nBusiness Opportunity\\nClerical/Administrative\\nConstruction/Facilities\\nConsumer Goods\\nCustomer Service\\nEducation/Training\\nEnergy/Utilities\\nEngineering\\nGovernment/Military\\nGreen\\n\\n\\n###\\n\\n\\nA spreadsheet of top science fiction movies and the year of release:\\n\\n\\nTitle|Year\\nStar Wars|1977\\nJaws|1975\\nThe Exorcist|1973\\nET|1982\\nAliens|1986\\nTerminator|1984\\nBlade Runner|1982\\nThe Thing|1982\\nJurassic Park|1993\\nThe Matrix|1999\\n\\n\\n###\\n\\n\\nA spreadsheet of hurricane and tropical storm counts with 13 columns:\\n\\n\\n\\\"Month\\\"| \\\"Average\\\"| \\\"2005\\\"| \\\"2006\\\"| \\\"2007\\\"| \\\"2008\\\"| \\\"2009\\\"| \\\"2010\\\"| \\\"2011\\\"| \\\"2012\\\"| \\\"2013\\\"| \\\"2014\\\"| \\\"2015\\\"\\n\\\"May\\\"|  0.1|  0|  0| 1| 1| 0| 0| 0| 2| 0|  0|  0  \\n\\\"Jun\\\"|  0.5|  2|  1| 1| 0| 0| 1| 1| 2| 2|  0|  1\\n\\\"Jul\\\"|  0.7|  5|  1| 1| 2| 0| 1| 3| 0| 2|  2|  1\\n\\\"Aug\\\"|  2.3|  6|  3| 2| 4| 4| 4| 7| 8| 2|  2|  3\\n\\\"Sep\\\"|  3.5|  6|  4| 7| 4| 2| 8| 5| 2| 5|  2|  5\\n\\\"Oct\\\"|  2.0|  8|  0| 1| 3| 2| 5| 1| 5| 2|  3|  0\\n\\\"Nov\\\"|  0.5|  3|  0| 0| 1| 1| 0| 1| 0| 1|  0|  1\\n\\\"Dec\\\"|  0.0|  1|  0| 1| 0| 0| 0| 0| 0| 0|  0|  1\\n    \\n###\\n\\n\\nA single column spreadsheet of days of the week:\\n\\n\\nDay|\\nMonday\\nTuesday\\nWednesday\\nThursday\\nFriday\\nSaturday\\nSunday\\n\\n\\n###\\n\\n\\nA two column spreadsheet of computer languages and their difficulty level:\",\n",
        "  temperature=0.3,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=[\"/n\"]\n",
        ")\n",
        "print(response.choices[0].text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Getting Started-GPT-3.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
